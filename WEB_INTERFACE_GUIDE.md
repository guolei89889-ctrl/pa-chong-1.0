# 🕷️ 民商法爆款文章爬虫 Web 界面使用指南

## 🚀 快速开始

### 1. 安装依赖
```bash
pip install -r requirements.txt
```

### 2. 启动Web界面
```bash
python start_web.py
```

### 3. 访问界面
启动后，浏览器会自动打开：http://localhost:5000

如果没有自动打开，请手动访问上述地址。

## 📋 界面功能说明

### 🎛️ 控制面板
- **🚀 开始爬取** - 启动爬虫任务
- **⏹️ 停止爬取** - 停止正在运行的爬虫
- **⚙️ 刷新配置** - 重新加载配置文件
- **📥 下载结果** - 下载爬取结果CSV文件

### 📊 状态监控
- **运行状态** - 显示当前爬虫状态（就绪/运行中）
- **进度** - 实时显示爬取进度百分比
- **总文章数** - 已获取的文章链接总数
- **当前处理** - 正在处理的文章序号
- **发现爆款** - 已发现的爆款文章数量

### 📋 运行日志
- 实时显示爬虫运行日志
- 包含时间戳和详细信息
- 自动滚动到最新日志

### ⚙️ 配置管理
- **配置文件编辑** - 可以直接编辑JSON配置文件
- **保存配置** - 保存修改后的配置
- **重置配置** - 重新加载当前配置

### 📊 爬取结果
- 检查结果文件是否存在
- 显示最后更新时间
- 一键下载结果文件

## ⚙️ 配置说明

配置文件采用JSON格式，主要包含以下部分：

### 目标平台配置
```json
{
    "target_platform": {
        "base_url": "https://your-target-website.com/law-section",
        "headers": {
            "User-Agent": "Mozilla/5.0..."
        },
        "selectors": {
            "article_links": "a.article-link",
            "title": "h1.article-title",
            "author": ".author-name",
            "publish_time": ".publish-date",
            "read_count": ".read-count",
            "like_count": ".like-count",
            "collect_count": ".collect-count",
            "summary": ".article-summary"
        }
    }
}
```

### 爬虫参数配置
```json
{
    "scraping": {
        "max_pages": 3,              // 最大抓取页数
        "max_retries": 3,            // 最大重试次数
        "retry_delay": 2,            // 重试延迟(秒)
        "request_timeout": 10,       // 请求超时(秒)
        "request_delay_min": 0.5,    // 最小请求延迟
        "request_delay_max": 2.0,    // 最大请求延迟
        "page_delay_min": 1.0,       // 最小翻页延迟
        "page_delay_max": 3.0        // 最大翻页延迟
    }
}
```

### 爆款标准配置
```json
{
    "bestseller_criteria": {
        "min_read_count": 10000,      // 最小阅读量
        "min_interaction_count": 1000  // 最小互动量(点赞+收藏)
    }
}
```

## 🎯 使用步骤

### 1. 配置目标网站
1. 点击"⚙️ 配置管理"标签页
2. 编辑配置文件，设置目标网站URL和选择器
3. 点击"💾 保存配置"保存修改

### 2. 开始爬取
1. 点击"🚀 开始爬取"按钮
2. 观察进度条和状态信息
3. 查看实时日志了解运行状态

### 3. 监控进度
- 实时查看爬取进度
- 观察发现的爆款文章数量
- 查看详细的运行日志

### 4. 获取结果
1. 爬取完成后，点击"📋 爬取结果"标签页
2. 点击"🔍 检查结果"确认结果文件
3. 点击"📥 下载结果"获取CSV文件

## 📁 输出文件

### CSV结果文件
文件：`minshangfa_bestsellers.csv`

包含字段：
- `title` - 文章标题
- `author` - 作者
- `publish_time` - 发布时间
- `read_count` - 阅读量
- `like_count` - 点赞数
- `collect_count` - 收藏数
- `summary` - 文章摘要
- `detail_url` - 文章详情页URL
- `is_bestseller` - 是否为爆款文章

### 日志文件
文件：`scraper.log`

包含详细的运行日志、错误信息和调试信息。

## ⚠️ 注意事项

### 法律合规
- 确保爬取行为符合目标网站的服务条款
- 尊重robots.txt文件规定
- 避免对目标网站造成过大负担
- 建议获得网站所有者的授权

### 技术注意
- 本项目仅供学习和研究使用
- 实际使用前需要适配目标网站的具体结构
- 合理设置请求延迟，避免被封IP
- 建议先进行小规模测试

### 配置建议
1. **选择器配置** - 使用浏览器开发者工具获取准确的选择器
2. **延迟设置** - 根据目标网站响应速度调整延迟参数
3. **爆款标准** - 根据实际平台特点调整判断标准
4. **日志级别** - 调试时可设置为DEBUG，生产环境用INFO

## 🔧 故障排除

### 常见问题

**Q: 爬虫无法启动**
A: 检查配置文件格式是否正确，确保所有必要字段都存在

**Q: 获取不到文章链接**
A: 检查选择器配置是否正确，确认目标网站结构是否变化

**Q: 程序运行缓慢**
A: 调整延迟参数，或检查网络连接状况

**Q: 结果被判定为异常**
A: 检查目标网站是否有反爬虫机制，考虑增加延迟或使用代理

### 日志分析
- 查看`scraper.log`文件获取详细错误信息
- 关注WARNING和ERROR级别的日志
- 根据时间戳定位问题发生时间

## 📞 技术支持

如遇到问题，请检查：
1. 配置文件格式是否正确
2. 网络连接是否正常
3. 目标网站是否可访问
4. 选择器是否匹配当前网页结构

## 🔄 更新日志

- v1.0.0 - 基础Web界面，支持配置管理、状态监控、日志显示
- 后续计划：添加数据可视化、定时任务、代理支持等功能